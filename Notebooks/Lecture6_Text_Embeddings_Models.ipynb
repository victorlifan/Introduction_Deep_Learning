{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5adfd5c-c155-444d-beeb-89161a51b239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0668f27-fd1f-4930-819f-fcbdb2702a9c",
   "metadata": {},
   "source": [
    "IMDB Movie Review Dataset (cleaned)\n",
    "- Originally from [here](https://ai.stanford.edu/~amaas/data/sentiment/)\n",
    "- Cleaned into a csv [here](https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c14c97e-da75-46c3-aadb-e1576bedcf8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('course_data/IMDB Dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a73f20c-ac25-407e-8318-77680e570778",
   "metadata": {},
   "source": [
    "## Automatic Tokenization with Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83e50c35-b1b7-429d-8004-fbc1fdcb9284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.1.0/en_core_web_sm-3.1.0-py3-none-any.whl (13.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.6 MB 3.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.2.0,>=3.1.0 in /Users/mruddy/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from en-core-web-sm==3.1.0) (3.1.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /Users/mruddy/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/mruddy/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.20.3)\n",
      "Requirement already satisfied: jinja2 in /Users/mruddy/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /Users/mruddy/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/mruddy/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (20.9)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /Users/mruddy/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.8.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/mruddy/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.25.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in /Users/mruddy/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/mruddy/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.6.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/mruddy/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/mruddy/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.7.4)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.7 in /Users/mruddy/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.7)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /Users/mruddy/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.3.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/mruddy/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.61.1)\n",
      "Requirement already satisfied: setuptools in /Users/mruddy/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (49.6.0.post20210108)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/mruddy/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/mruddy/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.0.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in /Users/mruddy/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/mruddy/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /Users/mruddy/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (5.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/mruddy/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.10.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mruddy/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/mruddy/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/mruddy/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/mruddy/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.10)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /Users/mruddy/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from typer<0.4.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mruddy/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# tool for text\n",
    "import spacy\n",
    "\n",
    "# load information about words\n",
    "!python3 -m spacy download en_core_web_sm\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c754d50b-148e-48a6-a470-0eac8236796e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you like original gut wrenching laughter you will like this movie. If you are young or old then you will love this movie, hell even my mom liked it.<br /><br />Great Camp!!!\n"
     ]
    }
   ],
   "source": [
    "some_text = df.iloc[9]['review']\n",
    "print(some_text)\n",
    "\n",
    "# automatically tokenize the text\n",
    "tokenized_text = nlp(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d3c905d-66ad-41b7-8ad5-ad0a85e41615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If\n",
      "you\n",
      "like\n",
      "original\n",
      "gut\n",
      "wrenching\n",
      "laughter\n",
      "you\n",
      "will\n",
      "like\n",
      "this\n",
      "movie\n",
      ".\n",
      "If\n",
      "you\n",
      "are\n",
      "young\n",
      "or\n",
      "old\n",
      "then\n",
      "you\n",
      "will\n",
      "love\n",
      "this\n",
      "movie\n",
      ",\n",
      "hell\n",
      "even\n",
      "my\n",
      "mom\n",
      "liked\n",
      "it.<br\n",
      "/><br\n",
      "/>Great\n",
      "Camp\n",
      "!\n",
      "!\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "# it's not perfect\n",
    "for token in tokenized_text:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62fae344-cb8d-411b-8c6a-ef3e226d7c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatization of wrenching is wrench\n",
      "wrenching is a VERB\n",
      "The fact that wrenching is a stop word is False\n"
     ]
    }
   ],
   "source": [
    "idx = 5\n",
    "\n",
    "token = tokenized_text[idx]\n",
    "\n",
    "# lemmatization\n",
    "print('Lemmatization of', token.text, 'is', token.lemma_)\n",
    "\n",
    "# part of speech tagging\n",
    "print(token.text, 'is a', token.pos_)\n",
    "\n",
    "# is it a stop word?\n",
    "print('The fact that', token.text, 'is a stop word is', token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12a84263-6ea6-4ebd-b092-9c69aa053e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you like original gut wrenching laughter you will like this movie.\n",
      "If you are young or old then you will love this movie, hell even my mom liked it.<br /><br />Great Camp!!!\n"
     ]
    }
   ],
   "source": [
    "# sentence segmentation\n",
    "for sentence in tokenized_text.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb184749-fc09-425e-bd27-4f56759b4c0e",
   "metadata": {},
   "source": [
    "- tons more fancy features!\n",
    "- Let's do a simple pipeline where we ignore non-alphabetic characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c291843-acb8-406c-bced-b8a477bfbf17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you like original gut wrenching laughter you will like this movie. If you are young or old then you will love this movie, hell even my mom liked it.  Great Camp!!!\n",
      "If you like original gut wrenching laughter you will like this movie If you are young or old then you will love this movie hell even my mom liked it Great Camp \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "a_review = df.iloc[9]['review']\n",
    "\n",
    "# remove those <br />s\n",
    "a_review = a_review.replace('<br />', ' ')\n",
    "print(a_review)\n",
    "\n",
    "# remove non-alphabetic characters\n",
    "a_review = re.sub(\"[^A-Za-z']+\", ' ', a_review)\n",
    "print(a_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c6a2ccd-516e-43ac-a485-8f03ca2032ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a6267d23b4e4497b24f51cf9bb613f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5ec32cba388a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# we let spaCy tokenize and lemmatize the text for us\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtokenized_review\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_review\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mcleaned_tokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemma_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenized_review\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stop\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m    998\u001b[0m                 \u001b[0merror_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_error_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m                 \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1001\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m                 \u001b[0;31m# This typically happens if a component is not initialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/spacy/pipeline/lemmatizer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverwrite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                     \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemma_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/spacy/pipeline/lemmatizer.py\u001b[0m in \u001b[0;36mrule_lemmatize\u001b[0;34m(self, token)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0;32melif\u001b[0m \u001b[0mform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                     \u001b[0mforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# disabling some fancy features of spacy for speed\n",
    "nlp = spacy.load('en_core_web_sm', disable = ['ner', 'parser'])\n",
    "\n",
    "rows = []\n",
    "for idx in tqdm(range(len(df))):\n",
    "    row = df.iloc[idx].copy()\n",
    "    \n",
    "    # first we remove numeric characters and lowercase everything\n",
    "    cleaned_review = re.sub(\"[^A-Za-z']+\", ' ', row['review'].replace('<br />', ' ')).lower()\n",
    "    \n",
    "    # we let spaCy tokenize and lemmatize the text for us\n",
    "    tokenized_review = nlp(cleaned_review)\n",
    "    cleaned_tokenized = [token.lemma_ for token in tokenized_review if ((not token.is_stop) or (' ' in token.text))]\n",
    "    \n",
    "    if len(cleaned_tokenized) > 1:\n",
    "        row['cleaned'] = ' '.join(cleaned_tokenized)\n",
    "    rows.append(row)\n",
    "df_clean = pd.DataFrame(rows)\n",
    "df_clean.head()\n",
    "df_clean.to_csv('course_data/IMDB_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "400239e5-9d76-462b-be23-c6165b7e2905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>reviewer mention watch oz episode hook right e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>think wonderful way spend time hot summer week...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>basically family little boy jake think zombie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>petter mattei love time money visually stunnin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             review sentiment  \\\n",
       "0           0  One of the other reviewers has mentioned that ...  positive   \n",
       "1           1  A wonderful little production. <br /><br />The...  positive   \n",
       "2           2  I thought this was a wonderful way to spend ti...  positive   \n",
       "3           3  Basically there's a family where a little boy ...  negative   \n",
       "4           4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "\n",
       "                                             cleaned  \n",
       "0  reviewer mention watch oz episode hook right e...  \n",
       "1  wonderful little production filming technique ...  \n",
       "2  think wonderful way spend time hot summer week...  \n",
       "3  basically family little boy jake think zombie ...  \n",
       "4  petter mattei love time money visually stunnin...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = pd.read_csv('course_data/IMDB_cleaned.csv')\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55cbaf1d-2fec-418e-982a-4855341570be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you like original gut wrenching laughter you will like this movie. If you are young or old then you will love this movie, hell even my mom liked it.<br /><br />Great Camp!!!\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'like original gut wrench laughter like movie young old love movie hell mom like great camp'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_clean.iloc[9]['review'])\n",
    "print('\\n')\n",
    "df_clean.iloc[9]['cleaned']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dd434d-a060-40b6-89b2-a7d745efe03c",
   "metadata": {},
   "source": [
    "## Prepare for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11b07a32-67ad-4952-9acf-8fbf925d6768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count words, send infrequent to unknown\n",
    "\n",
    "# let's get an idea of word frequency\n",
    "from collections import Counter\n",
    "\n",
    "reviews = [review.split(' ') for review in list(df_clean['cleaned'])]\n",
    "word_freq = Counter([token for review in reviews for token in review]).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2d58387-6570-40aa-8190-8fa84fa28c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('movie', 103272),\n",
       " ('film', 95394),\n",
       " ('like', 44224),\n",
       " ('good', 41452),\n",
       " (\"'\", 34217),\n",
       " ('time', 31502),\n",
       " ('character', 28356),\n",
       " ('watch', 27821),\n",
       " ('bad', 26610),\n",
       " ('story', 25272)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no surprises here\n",
    "word_freq[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f73b89b-60b9-4600-bd31-8e8ab6fdba73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('softheade', 1),\n",
       " ('macrophile', 1),\n",
       " ('arilin', 1),\n",
       " ('iraquis', 1),\n",
       " ('yaaayyyy', 1),\n",
       " ('ballplaying', 1),\n",
       " ('skynet', 1),\n",
       " ('homunculi', 1),\n",
       " ('eucharist', 1),\n",
       " ('escadrille', 1),\n",
       " ('yeeeecchh', 1),\n",
       " ('demono', 1),\n",
       " ('rohna', 1),\n",
       " ('pintos', 1),\n",
       " ('mottos', 1),\n",
       " ('kman', 1),\n",
       " ('farrellys', 1),\n",
       " ('nolin', 1),\n",
       " ('angelyne', 1),\n",
       " ('censorial', 1),\n",
       " ('burtolucci', 1),\n",
       " ('jossi', 1),\n",
       " ('ashknenazi', 1),\n",
       " ('effortful', 1),\n",
       " ('clatter', 1)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words only seen once\n",
    "word_freq[-25:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15e6d11b-bfeb-499d-bdb5-3f6bd9c62018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28510"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove words that appear infrequently\n",
    "word_freq = dict(word_freq)\n",
    "print(len(word_freq))\n",
    "min_freq = 5\n",
    "word_dict = {}\n",
    "\n",
    "# sending all the unknowns to 0\n",
    "i = 1\n",
    "for word in word_freq:\n",
    "    if word_freq[word] > min_freq:\n",
    "        word_dict[word] = i\n",
    "        i += 1\n",
    "    else:\n",
    "        word_dict[word] = 0\n",
    "\n",
    "# dictionary length        \n",
    "dict_length = max(word_dict.values()) + 1\n",
    "dict_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "481996b9-1b4d-457f-869e-3665b48f0b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87aa57e623c34a39850b13a1b8b6012c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1296\n"
     ]
    }
   ],
   "source": [
    "# to collate the tensors into batches, sentence need to be the same size\n",
    "# we could overwrite the collate function, or we could pick a max sentence size and pad\n",
    "\n",
    "max_length = 0\n",
    "for idx in tqdm(range(len(df_clean))):\n",
    "    row = df_clean.iloc[idx]\n",
    "    length = len(row['cleaned'].split(' '))\n",
    "    if length > max_length:\n",
    "        max_length = length\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d32d0945-6010-4589-9777-5777630b020e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  0,   0,   0,  ...,  56, 437, 271]), tensor(1.))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, df, word_dict, max_length):\n",
    "        self.df = df\n",
    "        self.word_dict = word_dict\n",
    "        self.sent_dict = {'negative': 0, 'positive': 1}\n",
    "        self.max_len = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        review = row['cleaned'].split(' ')\n",
    "        x = torch.zeros(self.max_len)\n",
    "        \n",
    "        # get review as a list of integers\n",
    "        for idx in range(len(review)):\n",
    "            \n",
    "            # we want to front pad for RNN\n",
    "            x[self.max_len - len(review) + idx] = self.word_dict[review[idx]]\n",
    "            \n",
    "        y = torch.tensor(self.sent_dict[row['sentiment']]).float()\n",
    "        \n",
    "        # embedding likes long tensors\n",
    "        return x.long(), y\n",
    "ds = IMDBDataset(df_clean, word_dict, max_length)\n",
    "next(iter(ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f05b5f-1c74-434c-bc72-b6a0f60dec48",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "658d591e-2aea-4faf-8c8f-6c4941524464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CBOW model for sentiment analysis\n",
    "# train the embedding during training\n",
    "class CBOW(nn.Module):\n",
    "    def __init__(self, dict_length, embedding_size):\n",
    "        super(CBOW, self).__init__()\n",
    "        # padding index turns off gradient for unknown tokens\n",
    "        self.word_emb = nn.Embedding(dict_length, embedding_size, padding_idx=0)\n",
    "        self.linear = nn.Linear(embedding_size, 1)\n",
    "        self.emb_size = embedding_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        sent_length = x.shape[1]\n",
    "        x = self.word_emb(x)\n",
    "        sent_length = torch.count_nonzero(x, dim=1)\n",
    "        x = torch.sum(x, dim=1) / sent_length\n",
    "        x = self.linear(x)\n",
    "        return torch.squeeze(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "138d8654-d202-4297-88f8-025cb96d4e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(ds, batch_size=1000, shuffle=True)\n",
    "x, y = next(iter(dl))\n",
    "\n",
    "cbow_model = CBOW(dict_length, 100)\n",
    "cbow_model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb4f2893-55e8-402c-ad06-a43ab14219e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def one_pass(model, dataloader, optimizer, lossFun, backwards=True, print_loss=False):\n",
    "    \n",
    "    if backwards == True:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    for x, y in tqdm(dataloader):\n",
    "        \n",
    "        y_pred = model(x)\n",
    "        loss = lossFun(y_pred, y)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if backwards == True:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    \n",
    "    if print_loss == True:\n",
    "        print(avg_loss)\n",
    "    \n",
    "    return avg_loss\n",
    "\n",
    "def one_pass_acc(model, dataloader, num_points):\n",
    "    model.eval()\n",
    "    total_incorrect = 0\n",
    "        \n",
    "    for x, y in dataloader:\n",
    "        y_pred = (torch.sigmoid(model(x)) > 0.5).float()\n",
    "        \n",
    "        total_incorrect += torch.count_nonzero(y - y_pred).item()\n",
    "        \n",
    "    percent_wrong = total_incorrect / num_points\n",
    "    return 1 - percent_wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59d73c4a-61a4-47c3-8d65-8f319f4f572e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "656cc2d428c64b08aa8615ebe0da4b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7db9160ed7364717978429a8c30145b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-e4c11f9b0890>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbow_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlossFun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-1f9bdbcd2ce3>\u001b[0m in \u001b[0;36mone_pass\u001b[0;34m(model, dataloader, optimizer, lossFun, backwards, print_loss)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-f263f06e22b2>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mreview\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleaned'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1501\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1503\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1505\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   2949\u001b[0m             \u001b[0;31m# if we are a copy, mark as such\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2950\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2951\u001b[0;31m             result = self._constructor_sliced(\n\u001b[0m\u001b[1;32m   2952\u001b[0m                 \u001b[0mnew_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2953\u001b[0m                 \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    362\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    543\u001b[0m                 \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mis_object_or_str_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_string_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_object_or_str_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0minferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_object_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \"\"\"\n\u001b[0;32m--> 228\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_is_dtype_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lossFun = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(cbow_model.parameters(), lr = 0.01)\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    print('Epoch: ', epoch)\n",
    "    \n",
    "    loss = one_pass(cbow_model, dl, optimizer, lossFun)\n",
    "    print('Loss: ', loss)\n",
    "    \n",
    "    acc = one_pass_acc(cbow_model, dl, len(ds))\n",
    "    print('Accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c4c25a5-3aa6-4325-b66e-2b1fc80daa06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN model for sentiment analysis (read Documentation for nn.RNN!)\n",
    "# train the embedding during training\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, dict_length, embedding_size):\n",
    "        super(RNN, self).__init__()\n",
    "        # padding index turns off gradient for unknown tokens\n",
    "        self.word_emb = nn.Embedding(dict_length, embedding_size, padding_idx=0)\n",
    "        \n",
    "        # RNN doesn't care about length of sequence\n",
    "        # RNN does care about the size of the word embedding\n",
    "        # hidden size dictates dimension of output of RNN\n",
    "        self.rnn = nn.RNN(input_size=embedding_size, hidden_size=1, batch_first=True)\n",
    "        \n",
    "        # PyTorch RNN outputs a sequence of same length as input\n",
    "        # For many to one, we can either use the final hidden state OR\n",
    "        # slap a linear layer on the output, taking in all the hidden states\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.word_emb(x)\n",
    "        \n",
    "        # RNN layer outputs a tuple, the output and the final hidden state\n",
    "        # taking the final hidden state as output\n",
    "        x = self.rnn(x)[1]\n",
    "    \n",
    "        return torch.squeeze(x)\n",
    "\n",
    "x, y = next(iter(dl))\n",
    "rnn_model = RNN(dict_length, 100)\n",
    "rnn_model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "32f8065b-0e51-42d7-b807-0c33d52add18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (word_emb): Embedding(28510, 100, padding_idx=0)\n",
       "  (rnn): RNN(100, 1, batch_first=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1883e871-61d8-4883-987c-7f36f98ee5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# does way better\n",
    "# hidden state updates each time it sees a new word\n",
    "# intuition: probably gets excited when it sees a word like bad/good and ignores the rest\n",
    "lossFun = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    print('Epoch: ', epoch)\n",
    "    \n",
    "    loss = one_pass(model, dl, optimizer, lossFun)\n",
    "    print('Loss: ', loss)\n",
    "    \n",
    "    acc = one_pass_acc(model, dl, len(ds))\n",
    "    print('Accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08415a2a-18ab-4cb2-bd4a-2da97ad9aa73",
   "metadata": {},
   "source": [
    "## Tools for Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18a60bae-91dc-4062-9710-f03e18c89acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mruddy/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
     ]
    }
   ],
   "source": [
    "# gensim is a great package for word embeddings\n",
    "# easy to train your own!\n",
    "import gensim.downloader\n",
    "\n",
    "# twitter embedding might be helpful for doing NLP related to social media!\n",
    "print(list(gensim.downloader.info()['models'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e699102d-2d7f-409a-a3c3-2b27144b6f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get the glove-wiki-gigaword-100\n",
    "# you can freeze the embedding for a model, finetune the embedding, or use it as a starting point for an embedding layer\n",
    "glove_emb = gensim.downloader.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe240be6-7cec-449d-9f82-fa6c6071ecb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dog', 0.8798074126243591),\n",
       " ('rabbit', 0.7424427270889282),\n",
       " ('cats', 0.732300341129303),\n",
       " ('monkey', 0.7288709878921509),\n",
       " ('pet', 0.7190139889717102),\n",
       " ('dogs', 0.7163873314857483),\n",
       " ('mouse', 0.6915250420570374),\n",
       " ('puppy', 0.6800068616867065),\n",
       " ('rat', 0.6641027331352234),\n",
       " ('spider', 0.6501135230064392)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can easily perform all the fancy features of word embeddings\n",
    "glove_emb.most_similar('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fac0527c-e0de-4898-85a6-782a304f00de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04581573,  0.05612466,  0.12537412, -0.11789493, -0.1162836 ,\n",
       "        0.12552294,  0.04842322, -0.02799585,  0.0120681 , -0.15672757,\n",
       "       -0.05774988,  0.02835106,  0.1434202 ,  0.04053723,  0.02792045,\n",
       "        0.19597296,  0.10424626,  0.01933913,  0.17506339,  0.10164274,\n",
       "        0.07978065,  0.04200767, -0.00260134, -0.14211448,  0.10990973,\n",
       "        0.22725299, -0.17471413, -0.09964842, -0.045272  ,  0.00473973,\n",
       "        0.02127272,  0.01661713,  0.10917152,  0.11604548,  0.15044893,\n",
       "        0.09069879, -0.05556507,  0.05005638,  0.13685384, -0.12099257,\n",
       "        0.0388505 ,  0.00877281, -0.06178614, -0.13657802, -0.04508745,\n",
       "        0.09164931, -0.15311994,  0.02025671,  0.11040384,  0.0133782 ,\n",
       "       -0.11352132,  0.04709963,  0.09360395,  0.16423851, -0.05806937,\n",
       "       -0.2663456 , -0.01970048,  0.05583891,  0.0825588 ,  0.02100086,\n",
       "        0.12343537,  0.17759547, -0.04652614,  0.10189674,  0.19720726,\n",
       "        0.23507151, -0.03247265,  0.04098373,  0.14655556,  0.04774258,\n",
       "       -0.19144061,  0.02675164, -0.00143837,  0.06551681, -0.02453705,\n",
       "        0.0539577 , -0.08126298,  0.00434761, -0.12043297,  0.08087405,\n",
       "        0.03882669, -0.08295171,  0.0369812 , -0.00647945, -0.15591595,\n",
       "       -0.02747793,  0.00873273, -0.01675286,  0.00974537,  0.04783187,\n",
       "        0.08983955, -0.03707248,  0.09164336,  0.01767462, -0.03608624,\n",
       "       -0.00302223, -0.14621027, -0.02883724,  0.02997231, -0.1418704 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normed cat vector\n",
    "cat_vec = glove_emb.get_vector('cat')\n",
    "cat_vec / np.linalg.norm(cat_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e696c59-43e8-46ee-a570-7c46a7eeb881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the weights\n",
    "weights = glove_emb.get_normed_vectors()\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd11e0ba-e00b-426d-892f-500df86c9451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch makes it easy to load the weights\n",
    "glove_emb_layer = nn.Embedding.from_pretrained(torch.tensor(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e83c862f-1bd5-44e6-83d6-6c78a54ab8fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0458,  0.0561,  0.1254, -0.1179, -0.1163,  0.1255,  0.0484, -0.0280,\n",
       "         0.0121, -0.1567, -0.0577,  0.0284,  0.1434,  0.0405,  0.0279,  0.1960,\n",
       "         0.1042,  0.0193,  0.1751,  0.1016,  0.0798,  0.0420, -0.0026, -0.1421,\n",
       "         0.1099,  0.2273, -0.1747, -0.0996, -0.0453,  0.0047,  0.0213,  0.0166,\n",
       "         0.1092,  0.1160,  0.1504,  0.0907, -0.0556,  0.0501,  0.1369, -0.1210,\n",
       "         0.0389,  0.0088, -0.0618, -0.1366, -0.0451,  0.0916, -0.1531,  0.0203,\n",
       "         0.1104,  0.0134, -0.1135,  0.0471,  0.0936,  0.1642, -0.0581, -0.2663,\n",
       "        -0.0197,  0.0558,  0.0826,  0.0210,  0.1234,  0.1776, -0.0465,  0.1019,\n",
       "         0.1972,  0.2351, -0.0325,  0.0410,  0.1466,  0.0477, -0.1914,  0.0268,\n",
       "        -0.0014,  0.0655, -0.0245,  0.0540, -0.0813,  0.0043, -0.1204,  0.0809,\n",
       "         0.0388, -0.0830,  0.0370, -0.0065, -0.1559, -0.0275,  0.0087, -0.0168,\n",
       "         0.0097,  0.0478,  0.0898, -0.0371,  0.0916,  0.0177, -0.0361, -0.0030,\n",
       "        -0.1462, -0.0288,  0.0300, -0.1419])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_idx = glove_emb.get_index('cat')\n",
    "glove_emb_layer(torch.tensor(cat_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ad35fba-d354-419b-9be1-2a38a76bc104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# make sure you turn off the gradients when training!\n",
    "for param in glove_emb_layer.parameters():\n",
    "    print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93624f77-ea54-4f87-98a1-8203624020ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "glove_emb_layer = nn.Embedding.from_pretrained(torch.tensor(weights), freeze=True)\n",
    "for param in glove_emb_layer.parameters():\n",
    "    print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883a5922-8576-4a82-9eb3-8b52bebfd473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a word2vec model\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# different options for how to perform word2vec training\n",
    "# check out documentation for more options related to sampling frequent vs. infrequent words\n",
    "w2v_model = Word2Vec(# only consider words that show up at least a 100 times\n",
    "                     min_count = 100, \n",
    "                     \n",
    "                     # context window\n",
    "                     window = 2,\n",
    "                     \n",
    "                     #size of embedding\n",
    "                     vector_size = 300)\n",
    "# has methods build_vocab and train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
